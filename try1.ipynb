{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#to generate same sequence of random numbers in whole file\n",
    "np.random.seed(2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#It is used during the training of a neural network to monitor a \n",
    "# specified metric (typically a validation metric) and stop training\n",
    "#  early if certain criteria are met. The purpose of using EarlyStopping\n",
    "#  is to prevent overfitting and to save time and resources when further\n",
    "#  training is unlikely to improve the model's performance.\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pylab import *\n",
    "import re\n",
    "from PIL import Image, ImageChops, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ela_image(path, quality):\n",
    "    # creating a temporary filename for an intermediate image\n",
    "    temp_filename = 'temp_file_name.jpg'\n",
    "    # filename for ela image that will be generated\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    \n",
    "    # open image and convert to RGB\n",
    "    image = Image.open(path).convert('RGB')\n",
    "\n",
    "    # save image as jpg and keep quality as before\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    \n",
    "    # calculate pixel difference between original image and RGB (new image) \n",
    "    # which will represents areas of image that have been altered.\n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    \n",
    "    # calculating minimum and maximum pixel values in the images\n",
    "    extrema = ela_image.getextrema()\n",
    "\n",
    "    # finds the maximum difference value among the extrema. This value is used to scale the ELA image.\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "\n",
    "    # ensuring max_diff is not zero to avoid division by zero.\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "\n",
    "    # calculates a scaling factor based on the maximum difference value. This factor\n",
    "    # is used to stretch the ELA image's pixel values across the full 0-255 range.\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    # enhances the brightness of the ELA image by applying the previously calculated \n",
    "    # scaling factor for making the manipulated regions stand out more distinctly.\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 images\n",
      "Processing 1000 images\n",
      "Processing 1500 images\n",
      "Processing 2000 images\n",
      "Processing 2500 images\n",
      "Processing 3000 images\n",
      "Processing 3500 images\n",
      "Processing 4000 images\n",
      "Processing 4500 images\n",
      "Processing 5000 images\n",
      "5123 5123\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "path= \"D:/major_project/dataset/real\"\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        # if filename.endswith('jpg') or filename.endswith('png') or filename.endswith('tif'):\n",
    "            full_path = os.path.join(dirname, filename)\n",
    "            X.append(prepare_image(full_path))\n",
    "            Y.append(1)\n",
    "            if len(Y) % 500 == 0:\n",
    "                print(f'Processing {len(Y)} images')\n",
    "\n",
    "random.shuffle(X)\n",
    "# X = X[:2100]\n",
    "# Y = Y[:2100]\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5500 images\n",
      "Processing 6000 images\n",
      "Processing 6500 images\n",
      "Processing 7000 images\n",
      "Processing 7500 images\n",
      "Processing 8000 images\n",
      "Processing 8500 images\n",
      "Processing 9000 images\n",
      "Processing 9500 images\n",
      "Processing 10000 images\n",
      "10246 10246\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/major_project/dataset/fake\"\n",
    "#path = '/content/drive/MyDrive/Colab Notebooks/Image_Detector/CASIA2/Fake'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        # if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            full_path = os.path.join(dirname, filename)\n",
    "            X.append(prepare_image(full_path))\n",
    "            Y.append(0)\n",
    "            if len(Y) % 500 == 0:\n",
    "                print(f'Processing {len(Y)} images')\n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting X into array \n",
    "X = np.array(X)\n",
    "#used when you have a target variable (labels or classes) that is represented as integers and you want to convert it into a binary matrix format suitable for training machine learning models, especially neural networks.\n",
    "# In Y there are two classes 1 for real and 0 for fake so to_categorical() converts this array into 2D array of labelled classes.\n",
    "# this Y will look like [[1,0],[0,1]] for 0 and 1 label.\n",
    "Y = to_categorical(Y, 2)\n",
    "# # Reshape image data for a convolutional neural network\n",
    "#  # Batch size, height, width, channels\n",
    "X = X.reshape(-1, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8196 8196\n",
      "2050 2050\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "# again converting 2D array to 1D array\n",
    "X = X.reshape(-1,1,1,1)\n",
    "print(len(X_train), len(Y_train))\n",
    "print(len(X_val), len(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models\n",
    "vgg16_model = load_model('model_vgg16_1_fake_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model = load_model('model_Xception_fake_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 134s 2s/step\n",
      "65/65 [==============================] - 75s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation set\n",
    "vgg16_predictions = vgg16_model.predict(X_val)\n",
    "xception_predictions = xception_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions using averaging\n",
    "ensemble_predictions = (vgg16_predictions + xception_predictions) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to classes\n",
    "ensemble_classes = np.argmax(ensemble_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy on Validation Set: 92.097561%\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot encoded labels back to single-column array\n",
    "Y_val_classes = np.argmax(Y_val, axis=1)\n",
    "\n",
    "# Evaluate ensemble performance\n",
    "ensemble_accuracy = accuracy_score(Y_val_classes, ensemble_classes)\n",
    "print(f'Ensemble Accuracy on Validation Set: {ensemble_accuracy * 100:.6f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_val: (2050, 2)\n",
      "Shape of ensemble_classes: (2050,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Y_val:\", Y_val.shape)\n",
    "print(\"Shape of ensemble_classes:\", ensemble_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_classes = np.argmax(Y_val, axis=1)\n",
    "class_names = ['fake', 'real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Ensemble Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.89      0.92      1009\n",
      "        real       0.90      0.95      0.92      1041\n",
      "\n",
      "    accuracy                           0.92      2050\n",
      "   macro avg       0.92      0.92      0.92      2050\n",
      "weighted avg       0.92      0.92      0.92      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_report = classification_report(Y_val_classes, ensemble_classes, target_names=class_names)\n",
    "print('Classification Report for Ensemble Model:')\n",
    "print(ensemble_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert ensemble_classes to one-hot encoded format\n",
    "ensemble_classes_onehot = to_categorical(ensemble_classes, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate confusion matrix for ensemble model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ensemble_conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensemble_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix for Ensemble Model:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(ensemble_conf_matrix)\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\swapn\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix for ensemble model\n",
    "ensemble_conf_matrix = confusion_matrix(Y_val, ensemble_classes)\n",
    "print('Confusion Matrix for Ensemble Model:')\n",
    "print(ensemble_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
