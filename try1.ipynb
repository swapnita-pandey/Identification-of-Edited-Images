{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#to generate same sequence of random numbers in whole file\n",
    "np.random.seed(2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#It is used during the training of a neural network to monitor a \n",
    "# specified metric (typically a validation metric) and stop training\n",
    "#  early if certain criteria are met. The purpose of using EarlyStopping\n",
    "#  is to prevent overfitting and to save time and resources when further\n",
    "#  training is unlikely to improve the model's performance.\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pylab import *\n",
    "import re\n",
    "from PIL import Image, ImageChops, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ela_image(path, quality):\n",
    "    # creating a temporary filename for an intermediate image\n",
    "    temp_filename = 'temp_file_name.jpg'\n",
    "    # filename for ela image that will be generated\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    \n",
    "    # open image and convert to RGB\n",
    "    image = Image.open(path).convert('RGB')\n",
    "\n",
    "    # save image as jpg and keep quality as before\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    \n",
    "    # calculate pixel difference between original image and RGB (new image) \n",
    "    # which will represents areas of image that have been altered.\n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    \n",
    "    # calculating minimum and maximum pixel values in the images\n",
    "    extrema = ela_image.getextrema()\n",
    "\n",
    "    # finds the maximum difference value among the extrema. This value is used to scale the ELA image.\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "\n",
    "    # ensuring max_diff is not zero to avoid division by zero.\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "\n",
    "    # calculates a scaling factor based on the maximum difference value. This factor\n",
    "    # is used to stretch the ELA image's pixel values across the full 0-255 range.\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    # enhances the brightness of the ELA image by applying the previously calculated \n",
    "    # scaling factor for making the manipulated regions stand out more distinctly.\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 images\n",
      "Processing 1000 images\n",
      "Processing 1500 images\n",
      "Processing 2000 images\n",
      "Processing 2500 images\n",
      "Processing 3000 images\n",
      "Processing 3500 images\n",
      "Processing 4000 images\n",
      "Processing 4500 images\n",
      "Processing 5000 images\n",
      "5123 5123\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "path= \"D:/major_project/dataset/real\"\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        # if filename.endswith('jpg') or filename.endswith('png') or filename.endswith('tif'):\n",
    "            full_path = os.path.join(dirname, filename)\n",
    "            X.append(prepare_image(full_path))\n",
    "            Y.append(1)\n",
    "            if len(Y) % 500 == 0:\n",
    "                print(f'Processing {len(Y)} images')\n",
    "\n",
    "random.shuffle(X)\n",
    "# X = X[:2100]\n",
    "# Y = Y[:2100]\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5500 images\n",
      "Processing 6000 images\n",
      "Processing 6500 images\n",
      "Processing 7000 images\n",
      "Processing 7500 images\n",
      "Processing 8000 images\n",
      "Processing 8500 images\n",
      "Processing 9000 images\n",
      "Processing 9500 images\n",
      "Processing 10000 images\n",
      "10246 10246\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/major_project/dataset/fake\"\n",
    "#path = '/content/drive/MyDrive/Colab Notebooks/Image_Detector/CASIA2/Fake'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        # if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            full_path = os.path.join(dirname, filename)\n",
    "            X.append(prepare_image(full_path))\n",
    "            Y.append(0)\n",
    "            if len(Y) % 500 == 0:\n",
    "                print(f'Processing {len(Y)} images')\n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting X into array \n",
    "X = np.array(X)\n",
    "#used when you have a target variable (labels or classes) that is represented as integers and you want to convert it into a binary matrix format suitable for training machine learning models, especially neural networks.\n",
    "# In Y there are two classes 1 for real and 0 for fake so to_categorical() converts this array into 2D array of labelled classes.\n",
    "# this Y will look like [[1,0],[0,1]] for 0 and 1 label.\n",
    "Y = to_categorical(Y, 2)\n",
    "# # Reshape image data for a convolutional neural network\n",
    "#  # Batch size, height, width, channels\n",
    "X = X.reshape(-1, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8196 8196\n",
      "2050 2050\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "# again converting 2D array to 1D array\n",
    "X = X.reshape(-1,1,1,1)\n",
    "print(len(X_train), len(Y_train))\n",
    "print(len(X_val), len(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models\n",
    "vgg16_model = load_model('model_vgg16_1_fake_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model = load_model('model_Xception_fake_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 134s 2s/step\n",
      "65/65 [==============================] - 75s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation set\n",
    "vgg16_predictions = vgg16_model.predict(X_val)\n",
    "xception_predictions = xception_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine predictions using averaging\n",
    "ensemble_predictions = (vgg16_predictions + xception_predictions) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to classes\n",
    "ensemble_classes = np.argmax(ensemble_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy on Validation Set: 92.097561%\n"
     ]
    }
   ],
   "source": [
    "# Convert one-hot encoded labels back to single-column array\n",
    "Y_val_classes = np.argmax(Y_val, axis=1)\n",
    "\n",
    "# Evaluate ensemble performance\n",
    "ensemble_accuracy = accuracy_score(Y_val_classes, ensemble_classes)\n",
    "print(f'Ensemble Accuracy on Validation Set: {ensemble_accuracy * 100:.6f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_val: (2050, 2)\n",
      "Shape of ensemble_classes: (2050,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Y_val:\", Y_val.shape)\n",
    "print(\"Shape of ensemble_classes:\", ensemble_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_classes = np.argmax(Y_val, axis=1)\n",
    "class_names = ['fake', 'real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Ensemble Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.89      0.92      1009\n",
      "        real       0.90      0.95      0.92      1041\n",
      "\n",
      "    accuracy                           0.92      2050\n",
      "   macro avg       0.92      0.92      0.92      2050\n",
      "weighted avg       0.92      0.92      0.92      2050\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_report = classification_report(Y_val_classes, ensemble_classes, target_names=class_names)\n",
    "print('Classification Report for Ensemble Model:')\n",
    "print(ensemble_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert ensemble_classes to one-hot encoded format\n",
    "ensemble_classes_onehot = to_categorical(ensemble_classes, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.897737556561086\n",
      "Recall: 0.9529298751200769\n",
      "F1-Score: 0.9245107176141659\n",
      "Cohen's Kappa: 0.8417584302588758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "\n",
    "# Calculate Precision\n",
    "precision = precision_score(Y_val_classes, ensemble_classes)\n",
    "\n",
    "# Calculate Recall\n",
    "recall = recall_score(Y_val_classes, ensemble_classes)\n",
    "\n",
    "# Calculate F1-Score\n",
    "f1 = f1_score(Y_val_classes, ensemble_classes)\n",
    "\n",
    "# Calculate Cohen's Kappa\n",
    "kappa = cohen_kappa_score(Y_val_classes, ensemble_classes)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-Score:', f1)\n",
    "print('Cohen\\'s Kappa:', kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate (FPR): 0.11199207135777998\n",
      "False Negative Rate (FNR): 0.04707012487992315\n"
     ]
    }
   ],
   "source": [
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(Y_val_classes, ensemble_classes)\n",
    "\n",
    "# False Positive Rate (FPR) is the ratio of false positives to all actual negatives\n",
    "fpr = cm[0, 1] / (cm[0, 0] + cm[0, 1])\n",
    "\n",
    "# False Negative Rate (FNR) is the ratio of false negatives to all actual positives\n",
    "fnr = cm[1, 0] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "print('False Positive Rate (FPR):', fpr)\n",
    "print('False Negative Rate (FNR):', fnr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
